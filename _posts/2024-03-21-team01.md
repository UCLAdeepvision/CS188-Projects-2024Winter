---
layout: post
comments: true
title: Post Template
author: UCLAdeepvision
date: 2024-01-01
---


> Ever since the advent of 3D graphics, computer graphics engineers have been looking for better, more streamlined ways to create models (data representing a 3D object), 
> a historically a tedious and long process. The goal of this post is to trace the history of 3D model generation through AI vision algorithms and suggest a potential
> method not just generating 3D models but pre-preparing them for use in animation and game development.
> 
> **To be clear we will be discussing how AI is leveraged to generate models in a format usable by the wider 3D community. We will not be discussing algorithms that choose
> to represent 3D data in a form unusable by traditional animation software such as Blender, Maya or Unity (i.e. unconverted NERF data).**


<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Main Content
3D graphics were a revolution when they were introduced. For the first time, computer were showing virtual world within the screen, not just flat images and text. As 3D graphics
have improved, the technology has equally grown in complexity. One of the core parts of 3D graphics are 3D models, data containing information about how to display a 3D object. 
The job of a 3D modeller is therefore converting objects in the real world into 3D models such that they can be used in other applications.

![YOLO]({{ '/assets/images/team1/3dModelConversion.png' | relative_url }})
{: style="width: 400px; max-width: 100%;"}
*Fig 1. A real soccer ball versus it's counterpart as a 3D model.* [1] [2]

The 
While there are many different ways models can be stored, this
post will focus on three commonly used formats by animators and game designers, point clouds, voxels, and meshes. 

It should be noted that regardless of the initial format, the **end-goal** of all these methods is to generate a mesh. We won't note the conversion
process between these formats extensively as the conversion process is already well-defined by external, non-AI related tools, **unless** it is related to
the algorithm being discussed.

### Voxels

The simplest definition, a model defined by voxels is just a collection of 3D points in XYZ space snapped to a three-dimensional grid of fixed size. These
are typically the easiest to store (as they're just lists of three numbers) and the easiest to comprehend, but doesn't yield the best results. Due to the 
grid like nature of how voxels are defined, it is a trade-off between a smooth, detailed model or a space-efficient model storage-wise. However, voxel are
a decent precursor to a later model type as a base template. In terms of rendering, voxels simply fill in cubes where points are defined, giving the overall
model a boxy shape. While not ideal, 3D modellers are able to work with this format relatively easily by "filling in cubes", and given certain aesthetics the
"voxelated" look may even be desired. 


## Point-Cloud

Point clouds are similar to voxels in the way that they're also defined as a collection of points in XYZ space. However, the points in a point cloud aren't restricted
to any set grid, and therefore can exist in any place in 3D space. The trade-off for this level of detail is that point clouds don't have a simple method
to render them without some sort of conversion or lost of accuracy. For example, point clouds may be first converted to a voxel representation via rounding, then
rendered that way. Another is to send a high density of ray-casts out from the rendering camera and approximating which points each ray would
hit to a certain threshold. Overall though, point clouds are unideal to work with as a 3D modeller for it's extremely hard to visualize what a point
cloud would look like post-rendering, and it is highly unclear how an artist would "edit" a point cloud. The prevalence of point clouds is mainly 
due to the fact that it's the best format for live capture of real-world 3D data, and as such there are many, well-developed tools that can do the
conversion of point-clouds for us.

### Mesh
Meshes are the most common way 3D models are stored as their definition is easy to understand while giving 3D artists the greatest amount of
control over the shape of a model. They are defined by three different aspects, _points_, _edges_, and _faces_. 

Points are the simplest concept to grasp, they're a list of discrete points that define the vertices of a 3D
object. The most important data associated with points are their coordinates in XYZ space, for this data is absolutely
required for the definition of a mesh's shape. However, additional data may also be stored per point. For example, data associated
with the normal of each point may be stored, which is later used to render (displaying 3D data) the object. Normals define which direction
is considered "pointing" outwards at a specific point, ensuring that the model isn't inside out and additionally can be used with
interpolation to smooth the appearance of meshes without the need for more points.

Edges are edges of the 3D model, the exact same edges of a 3D shape. They're defined as pairs of points, and typically don't have any
additional data associated with them other than the two point that define them.

Faces are the visible parts of a mesh, and the parts that are actually displayed when rendering a 3D model. They are defined by a list of points,
and the normal of a face is defined as the cross product of the vectors between the points. In most meshes, faces are triangles as it significantly
simplifies the calculation of face normals, defining the two required vectors for the cross product as a vector from point 1 to
point 2 and a vector from point 1 to point 3. Because of this, the points that define the face must be a counterclockwise order, thus meaning
that the ordering of points is extremely important.

## Basic Syntax
### Image
Please create a folder with the name of your team id under /assets/images/, put all your images into the folder and reference the images in your main content.

You can add an image to your survey like this:
![YOLO]({{ '/assets/images/UCLAdeepvision/object_detection.png' | relative_url }})
{: style="width: 400px; max-width: 100%;"}
*Fig 1. YOLO: An object detection method in computer vision* [1].

Please cite the image if it is taken from other people's work.


### Table
Here is an example for creating tables, including alignment syntax.

|             | column 1    |  column 2     |
| :---        |    :----:   |          ---: |
| row1        | Text        | Text          |
| row2        | Text        | Text          |



### Code Block
```
# This is a sample code block
import torch
print (torch.__version__)
```


### Formula
Please use latex to generate formulas, such as:

$$
\tilde{\mathbf{z}}^{(t)}_i = \frac{\alpha \tilde{\mathbf{z}}^{(t-1)}_i + (1-\alpha) \mathbf{z}_i}{1-\alpha^t}
$$

or you can write in-text formula $$y = wx + b$$.

### More Markdown Syntax
You can find more Markdown syntax at [this page](https://www.markdownguide.org/basic-syntax/).

## Reference
Please make sure to cite properly in your work, for example:

[1] ["Soccer Ball"](https://sketchfab.com/3d-models/soccer-ball-88590cf1e42e44bfb85ce3b6b1959648) by [tinmanjuggernaut](https://sketchfab.com/tinmanjuggernaut) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)
[2] ["Giant Soccer Ball"](https://upload.wikimedia.org/wikipedia/commons/c/c3/Giant_Soccer_Ball.jpg) by A. Scott Fulkerson / Circle Jerk Productions (TM) is licensed under [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)

---
